# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/08_CNN_Interpreter.ipynb (unless otherwise specified).

__all__ = ['show_heatmap', 'create_batch', 'GuidedBackprop', 'generate_cam', 'CamImage', 'get_at', 'show_at',
           'show_cam_batch', 'BaseInterpreter', 'batch_none', 'CamInterpreter']

# Cell
from fastai2.vision.all import *
from .core import arch_summary, get_module, min_max_scale
from .transforms import to_grayscale
import copy
import gc

# Cell
def show_heatmap(cam,sz,ax=None,alpha=0.6,interpolation='bilinear',
                 cmap='magma'):
  show_image(min_max_scale(cam),ax=ax,
             extent=(1,sz,sz,1),alpha=alpha,
             interpolation=interpolation,cmap=cmap)

# Cell
def create_batch(dls:DataLoaders,fname,lbl_idx,size=None,method=None):
  """Create test_batch from filename and label index
  Refer `dls.vocab` to find validation index
  In case you want to Resize an image, use `size` and `method` parameters
  Default method of cropping is set to 'squish' cosidering the use-case
  """
  img = PILImage.create(fname)
  if size is not None:
    method = ifnone(method,'squish')
    resize = Resize(size,method=method)
    img = resize(img)
  xb, = first(dls.test_dl([img]))
  yb = dls.categorize(dls.vocab[lbl_idx])[None]
  return xb,yb

# Cell
class GuidedBackprop:
    "Produces gradients generated with guided back propagation from the given image"
    def __init__(self, model,act_cls:nn.Module=nn.ReLU):
        self.model = model.requires_grad_().eval()
        self.act_cls = act_cls
        self._fmaps = L()
        self._hooks = L()
        self._register_hooks()

    def hook(self,module,hook_fn,grad=False):
      if not grad:
        self._hooks += module.register_forward_hook(hook_fn)
      else:
        self._hooks += module.register_backward_hook(hook_fn)

    def _register_hooks(self):
        """Updates relu activation functions so that
        1- stores output in forward pass
        2- imputes zero for gradient values that are less than zero
        """
        def store_activations_hook(module,input,output):
            "Store forward pass outputs (Activaton Maps)"
            self._fmaps += output


        def clamp_gradients_hook(module,grad_in, grad_out):
            "If there is a negative gradient, change it to zero"
            # Get last forward output
            fmap = self._fmaps[-1]
            fmap[fmap > 0] = 1
            grad_out_new = fmap * F.relu(grad_in[0])
            del self._fmaps[-1]  # Remove last forward output
            return (grad_out_new,)

        # hook up ReLUs (activation layers)
        for name, module in self.model.named_modules():
            if isinstance(module, self.act_cls):
              self.hook(module,store_activations_hook)
              self.hook(module,clamp_gradients_hook,grad=True)

    def remove_hooks(self):
      for hook in self._hooks:
        hook.remove()
      gc.collect()

    def guided_backprop(self,xb,yb=None):
      xb = xb.clone() # To avoid modifying original tensors
      first_conv = flatten_model(self.model)[0]

      def hook_first(m,grad_in,grad_out): return grad_in[0]

      with Hook(first_conv,hook_first,is_forward=False) as reconstruction:
        xb.requires_grad_()
        if not xb.grad is None:
          xb.grad.zero_()
        y_preds = self.model(xb)
        self.model.zero_grad()
        if yb is None:
          y = y_preds.argmax().item()
        else: y = yb.item()
        y_preds[0,y].backward(retain_graph=True)
        gbprop = reconstruction.stored[0]
        self.remove_hooks()
        return gbprop

# Cell
def generate_cam(model,xb,act_path:list=[0],wt_path:list=[1,-1],with_preds=False):
    """Show CAM for a given image
    `act_path`: list of indices to reach activation maps layer
    `wt_path`: list of indices to reach weight layer
    """
    if len(xb.shape)==3: xb= xb[None]

    act_layer = get_module(model,act_path)
    wt_layer = get_module(model,wt_path)
    with hook_output(act_layer) as hook:
      y_preds = model(xb)
      act = hook.stored
      cam = torch.einsum('ck,nkij->ncij', wt_layer.weight, act)

      #cleanup: to prevent memory-error
      del act,xb
      torch.cuda.empty_cache()

    if with_preds: return cam, y_preds
    return cam

# Cell
class CamImage:
  def __init__(self,x_dec,y_dec,pred_cls,cam:torch.Tensor):
    store_attr(self,'x_dec,y_dec,pred_cls,cam')

  def show(self,ctx=None,merge=True):
    imsize = 5 if merge else 7
    if ctx is None:
      _,ctx = subplots(1,1 + int(not merge),figsize=(imsize,imsize))
    else:
      if not is_listy(ctx):
        # ctx is available, but only one, so merge
        merge=True
        ctx = [ctx]
      elif len(ctx)==2:
        # two ctx are available, so merge=False
        merge=False

    ax = self.x_dec.show(ctx=ctx[0])
    ax = self.y_dec.show(ctx=ax)
    is_correct = self.pred_cls==self.y_dec
    ax = show_title(self.pred_cls,ctx=ax,color='green' if is_correct else 'red')
    alpha = 0.6 if merge else 1.
    show_heatmap(self.cam,self.x_dec.shape[-1],ax=ctx[int(not merge)],alpha=alpha)

# Cell
def get_at(batch_dec,cam_batch,y_preds,idx,for_cls=None)->CamImage:
  x,y = batch_dec[idx]
  cam_i = cam_batch[idx]
  del cam_batch # we don't need batch anymore, free-up memory

  if for_cls is not None:
    del y_preds
    class_id = for_cls
  else:
    class_id = y_preds[idx].argmax(-1).item()
  return CamImage(x,y,dls.vocab[class_id],cam_i[class_id])

def show_at(model,xb,yb,idx,merge=True,for_cls=None):
  xib,yib = xb[idx][None],yb[idx][None]
  batch_dec = dls.decode_batch((xib,yib))
  cam_b,y_preds = generate_cam(model,xib,with_preds=True)
  get_at(batch_dec,cam_b,y_preds,idx=0,for_cls=for_cls).show(merge=merge)

# Cell
def show_cam_batch(xb,yb,cam_batch,y_preds,max_n=9,merge=True,nrows=None, ncols=None, figsize=None):
  ctxs = get_grid(min(xb.shape[0],max_n),double=(not merge),add_vert=4,title='Target/Prediction')
  batch_dec = dls.decode_batch((xb,yb))
  getter = partial(get_at,batch_dec,cam_batch,y_preds)
  if merge:
    for idx,ctx in enumerate(ctxs):
      cam_img = getter(idx)
      cam_img.show(ctx=ctx)
  else:
    for idx,ctx in enumerate(zip(ctxs[0::2],ctxs[1::2])):
      cam_img = getter(idx)
      cam_img.show(ctx=ctx)

# Cell
class BaseInterpreter:
  def __init__(self,model:nn.Module,dls:DataLoaders,valid_dl:DataLoader=None):
    self.model = copy.copy(model.eval())
    self.dls = dls
    self.valid_dl = ifnone(valid_dl,copy.copy(dls.valid))
    self.valid_dl.shuffle=True

  @classmethod
  def from_learner(cls,learn:Learner,ds_idx=1,dl=None):
    if dl is None: dl = learn.dls[ds_idx]
    return cls(learn.model,learn.dls,dl)

  def is_cam_compatible(self,model:nn.Module=None):
    """Check whether model is compatible for CAM
    The requirement is `GlobalAveragePooling` should be the penultimate layer
    """
    avg_idx=-1
    if model is None: model = self.model
    layers = flatten_model(model)
    for idx,layer in enumerate(layers):
      if isinstance(layer,(nn.AvgPool2d,nn.AdaptiveAvgPool2d)):
        avg_idx = len(layers) - idx - 1
    if not avg_idx in [1,2]: return False #AvgPool is not penultimate
    return True

  def label_list(self):
    "Show Class labels and indices (pretty-print `dls.vocab`)"
    df = pd.DataFrame(self.dls.vocab,columns=['category'])
    return df

# Cell
def batch_none(xb,yb):
  return xb is None and yb is None

class CamInterpreter(BaseInterpreter):

  @delegates(generate_cam)
  def generate(self,xb=None,yb=None,**kwargs):
    if batch_none(xb,yb):
      xb,yb = self.valid_dl.one_batch()
    return generate_cam(self.model,xb,**kwargs)

  @delegates(show_cam_batch,but=['xb,yb,cam_batch,y_preds'])
  def show_batch(self,xb=None,yb=None, **kwargs):
    if batch_none(xb,yb):
      xb,yb = self.valid_dl.one_batch()
    cam_batch,y_preds = self.generate(xb,with_preds=True)
    show_cam_batch(xb,yb,cam_batch,y_preds,**kwargs)