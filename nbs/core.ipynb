{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core\n",
    "> Core utility functions used in the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai2.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _is_sequential(o): return o.__class__.__name__=='Sequential'\n",
    "def _is_fn(o): return type(o)==types.FunctionType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_module(o,i):\n",
    "  \"Recursively get the module from list of indices\"\n",
    "  if is_listy(i):\n",
    "    m = get_module(o,i[0])\n",
    "    if len(i)==1: return m\n",
    "    return get_module(m,i[1:])\n",
    "  return o[i] if is_listy(o) else list(o.children())[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the times, we want to extract nested module in architecture; while some modules support indexing (Sequential), some don't. This function enables you to access nested modules in a numpy-like indexing. When coupled with `arch_summary`, we can effortlessly explore the pytorch models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def arch_summary(arch,idx=None,verbose:bool=False):\n",
    "  r\"\"\"Short architecture summary, used for holistic understanding of model\n",
    "  Args:\n",
    "      arch: a function or model object\n",
    "      idx (int,list): an integer or list of indices to reach desired module in the architecture\n",
    "      verbose (bool): If True, will list the names of sub-modules\n",
    "  \"\"\"\n",
    "  model = arch(False) if _is_fn(arch) else arch\n",
    "  if idx is not None:\n",
    "    model = get_module(model,idx)\n",
    "  for i, l in enumerate(model.children()):\n",
    "      n_layers = len(l if _is_sequential(l) else flatten_model(l))\n",
    "      print(f'({i:<2}) {l.__class__.__name__:<17}: {n_layers:<4}layers')\n",
    "      if verbose and l.has_children:\n",
    "        layers = [x.__class__.__name__ for x in l.children()]\n",
    "        for il in layers:\n",
    "          print(\" \"*5,il)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "densenet121 from torchvision has first `_DenseLayer` at index [0,4,0], we can look at its brief summary as follows:\n",
    "\n",
    "_(NB: densenet121 implementation is divided into two modules, body and head, directly skipping to body)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0 ) Conv2d           : 1   layers\n",
      "(1 ) BatchNorm2d      : 1   layers\n",
      "(2 ) ReLU             : 1   layers\n",
      "(3 ) MaxPool2d        : 1   layers\n",
      "(4 ) _DenseBlock      : 36  layers\n",
      "(5 ) _Transition      : 4   layers\n",
      "(6 ) _DenseBlock      : 72  layers\n",
      "(7 ) _Transition      : 4   layers\n",
      "(8 ) _DenseBlock      : 144 layers\n",
      "(9 ) _Transition      : 4   layers\n",
      "(10) _DenseBlock      : 96  layers\n",
      "(11) BatchNorm2d      : 1   layers\n"
     ]
    }
   ],
   "source": [
    "arch_summary(densenet121,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0 ) BatchNorm2d      : 1   layers\n",
      "(1 ) ReLU             : 1   layers\n",
      "(2 ) Conv2d           : 1   layers\n",
      "(3 ) BatchNorm2d      : 1   layers\n",
      "(4 ) ReLU             : 1   layers\n",
      "(5 ) Conv2d           : 1   layers\n"
     ]
    }
   ],
   "source": [
    "arch_summary(densenet121,[0,4,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if you really want to know go deeper, you may set `verbose=True` and `arch_summary` will go 2 depth down. For the simplicity, I'm keeping it to the depth of 2, since you can always have a detailed summary using `fastai2`'s patched summary method on module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0 ) Conv2d           : 1   layers\n",
      "(1 ) BatchNorm2d      : 1   layers\n",
      "(2 ) ReLU             : 1   layers\n",
      "(3 ) MaxPool2d        : 1   layers\n",
      "(4 ) _DenseBlock      : 36  layers\n",
      "      _DenseLayer\n",
      "      _DenseLayer\n",
      "      _DenseLayer\n",
      "      _DenseLayer\n",
      "      _DenseLayer\n",
      "      _DenseLayer\n",
      "(5 ) _Transition      : 4   layers\n",
      "      BatchNorm2d\n",
      "      ReLU\n",
      "      Conv2d\n",
      "      AvgPool2d\n",
      "(6 ) _DenseBlock      : 72  layers\n",
      "      _DenseLayer\n",
      "      _DenseLayer\n",
      "      _DenseLayer\n",
      "      _DenseLayer\n",
      "      _DenseLayer\n",
      "      _DenseLayer\n",
      "      _DenseLayer\n",
      "      _DenseLayer\n",
      "      _DenseLayer\n",
      "      _DenseLayer\n",
      "      _DenseLayer\n",
      "      _DenseLayer\n",
      "(7 ) _Transition      : 4   layers\n",
      "      BatchNorm2d\n",
      "      ReLU\n",
      "      Conv2d\n",
      "      AvgPool2d\n",
      "(8 ) _DenseBlock      : 144 layers\n",
      "      _DenseLayer\n",
      "      _DenseLayer\n",
      "      _DenseLayer\n",
      "      _DenseLayer\n",
      "      _DenseLayer\n",
      "      _DenseLayer\n",
      "      _DenseLayer\n",
      "      _DenseLayer\n",
      "      _DenseLayer\n",
      "      _DenseLayer\n",
      "      _DenseLayer\n",
      "      _DenseLayer\n",
      "      _DenseLayer\n",
      "      _DenseLayer\n",
      "      _DenseLayer\n",
      "      _DenseLayer\n",
      "      _DenseLayer\n",
      "      _DenseLayer\n",
      "      _DenseLayer\n",
      "      _DenseLayer\n",
      "      _DenseLayer\n",
      "      _DenseLayer\n",
      "      _DenseLayer\n",
      "      _DenseLayer\n",
      "(9 ) _Transition      : 4   layers\n",
      "      BatchNorm2d\n",
      "      ReLU\n",
      "      Conv2d\n",
      "      AvgPool2d\n",
      "(10) _DenseBlock      : 96  layers\n",
      "      _DenseLayer\n",
      "      _DenseLayer\n",
      "      _DenseLayer\n",
      "      _DenseLayer\n",
      "      _DenseLayer\n",
      "      _DenseLayer\n",
      "      _DenseLayer\n",
      "      _DenseLayer\n",
      "      _DenseLayer\n",
      "      _DenseLayer\n",
      "      _DenseLayer\n",
      "      _DenseLayer\n",
      "      _DenseLayer\n",
      "      _DenseLayer\n",
      "      _DenseLayer\n",
      "      _DenseLayer\n",
      "(11) BatchNorm2d      : 1   layers\n"
     ]
    }
   ],
   "source": [
    "arch_summary(densenet121,0,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('fastai2': conda)",
   "language": "python",
   "name": "python37664bitfastai2condaf3e9781124be45a78083b472977e8c5c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
