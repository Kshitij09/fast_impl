{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial- Explore CNN architectures using arch_summary\n",
    "> Exploring CNN architectures from torchvision, fastai2 and pytorch-image-models (timm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai2.vision.all import *\n",
    "from fast_impl.core import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`arch_summary` function plays major role while deciding parameter groups for discriminative learning. It gives a brief summary of architecture and is independant of `DataLoaders` or `Learner`. Thus we could use this function to assess the correctness of architecture before passing it to learner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fastai2 models\n",
    "Let's first quickly go through `XResNet` series offered by `fastai2`\n",
    "\n",
    "```python\n",
    "def xresnet18 (pretrained=False, **kwargs): return _xresnet(pretrained, 1, [2, 2,  2, 2], **kwargs)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0 ) ConvLayer        : 3   layers\n",
      "(1 ) ConvLayer        : 3   layers\n",
      "(2 ) ConvLayer        : 3   layers\n",
      "(3 ) MaxPool2d        : 1   layers\n",
      "(4 ) Sequential       : 2   layers\n",
      "(5 ) Sequential       : 2   layers\n",
      "(6 ) Sequential       : 2   layers\n",
      "(7 ) Sequential       : 2   layers\n",
      "(8 ) AdaptiveAvgPool2d: 1   layers\n",
      "(9 ) Flatten          : 1   layers\n",
      "(10) Dropout          : 1   layers\n",
      "(11) Linear           : 1   layers\n"
     ]
    }
   ],
   "source": [
    "arch_summary(xresnet18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the Sequential layers from 4-7 all having two child layers, that's the meaning of `[2,2,2,2]` in the model definition. Let's go deeper and check what are those children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0 ) ConvLayer        : 3   layers\n",
      "      Conv2d\n",
      "      BatchNorm2d\n",
      "      ReLU\n",
      "(1 ) ConvLayer        : 3   layers\n",
      "      Conv2d\n",
      "      BatchNorm2d\n",
      "      ReLU\n",
      "(2 ) ConvLayer        : 3   layers\n",
      "      Conv2d\n",
      "      BatchNorm2d\n",
      "      ReLU\n",
      "(3 ) MaxPool2d        : 1   layers\n",
      "(4 ) Sequential       : 2   layers\n",
      "      ResBlock\n",
      "      ResBlock\n",
      "(5 ) Sequential       : 2   layers\n",
      "      ResBlock\n",
      "      ResBlock\n",
      "(6 ) Sequential       : 2   layers\n",
      "      ResBlock\n",
      "      ResBlock\n",
      "(7 ) Sequential       : 2   layers\n",
      "      ResBlock\n",
      "      ResBlock\n",
      "(8 ) AdaptiveAvgPool2d: 1   layers\n",
      "(9 ) Flatten          : 1   layers\n",
      "(10) Dropout          : 1   layers\n",
      "(11) Linear           : 1   layers\n"
     ]
    }
   ],
   "source": [
    "arch_summary(xresnet18,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hmm... those are indeed `ResBlocks`, but what is `ResBlock`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0 ) Sequential       : 2   layers\n",
      "      ConvLayer\n",
      "      ConvLayer\n",
      "(1 ) Sequential       : 0   layers\n",
      "(2 ) ReLU             : 1   layers\n"
     ]
    }
   ],
   "source": [
    "arch_summary(xresnet18,[4,0],verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Residual Block](images/residual_block.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to [ResNet](https://arxiv.org/abs/1512.03385), we should have two weight layers, an identity (skip-connection) block and activation (ReLU), which is exactly `ResBlock` implements, with many [tweaks](https://arxiv.org/abs/1812.01187) introduced in the following years to improve the performance. A `ConvLayer` in fastai is basically Conv2D --> BatchNorm --> Activation (ReLU) but we can infinitely customize this building block; you might want to have a look at its [implementation](https://github.com/fastai/fastai2/blob/a1204f7ba005fe92e09763f2b68dd9fb4ef11846/fastai2/layers.py#L230). For rest of `xresnet` family, we'll have the exact same architecture but with more \"groups\" of `ResBlock`, such as\n",
    "```python\n",
    "def xresnet34 (pretrained=False, **kwargs): return _xresnet(pretrained, 1, [3, 4,  6, 3], **kwargs)\n",
    "def xresnet50 (pretrained=False, **kwargs): return _xresnet(pretrained, 4, [3, 4,  6, 3], **kwargs)\n",
    "def xresnet101(pretrained=False, **kwargs): return _xresnet(pretrained, 4, [3, 4, 23, 3], **kwargs)\n",
    "def xresnet152(pretrained=False, **kwargs): return _xresnet(pretrained, 4, [3, 8, 36, 3], **kwargs)\n",
    "```\n",
    "\n",
    "`xresnet34` will have 4 groups having `[3, 4, 6, 3]` no. of `ResBlocks` and so on. We do get other variants of these base architecutures but as they're still experimental, I'll skip them for now. Now let's have a look at some architectures from torchvision. I've already explained `densenet121` in [core](core.ipynb) notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torchvision models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
