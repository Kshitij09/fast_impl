{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "!curl https://gist.githubusercontent.com/Kshitij09/63b7d141348fd9c9a421c23955f4fff6/raw | bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai2.vision.models.xresnet import *\n",
    "from torchvision.models import resnet50\n",
    "from fast_impl.core import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`arch_summary` function plays major role while deciding parameter groups for discriminative learning rates. It gives a brief summary of architecture and is independant of input being passed. Thus we could use this function to understand architecture in a glance. We'll briefly explore various vision models from torchvision and [pytorch-image-models](https://github.com/rwightman/pytorch-image-models) to understand the use of `arch_summary`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XResNet (fastai2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first quickly go through `XResNet` series offered by `fastai2`\n",
    "\n",
    "```python\n",
    "def xresnet18 (pretrained=False, **kwargs): return _xresnet(pretrained, 1, [2, 2,  2, 2], **kwargs)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 ] ConvLayer        : 3   layers\n",
      "[1 ] ConvLayer        : 3   layers\n",
      "[2 ] ConvLayer        : 3   layers\n",
      "[3 ] MaxPool2d        : 1   layers\n",
      "[4 ] Sequential       : 2   layers\n",
      "[5 ] Sequential       : 2   layers\n",
      "[6 ] Sequential       : 2   layers\n",
      "[7 ] Sequential       : 2   layers\n",
      "[8 ] AdaptiveAvgPool2d: 1   layers\n",
      "[9 ] Flatten          : 1   layers\n",
      "[10] Dropout          : 1   layers\n",
      "[11] Linear           : 1   layers\n"
     ]
    }
   ],
   "source": [
    "arch_summary(xresnet18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the Sequential layers from 4-7 all having two child layers, that's the meaning of `[2,2,2,2]` in the model definition. Let's go deeper and check what are these two children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 ] ConvLayer        : 3   layers\n",
      "      Conv2d\n",
      "      BatchNorm2d\n",
      "      ReLU\n",
      "[1 ] ConvLayer        : 3   layers\n",
      "      Conv2d\n",
      "      BatchNorm2d\n",
      "      ReLU\n",
      "[2 ] ConvLayer        : 3   layers\n",
      "      Conv2d\n",
      "      BatchNorm2d\n",
      "      ReLU\n",
      "[3 ] MaxPool2d        : 1   layers\n",
      "[4 ] Sequential       : 2   layers\n",
      "      ResBlock\n",
      "      ResBlock\n",
      "[5 ] Sequential       : 2   layers\n",
      "      ResBlock\n",
      "      ResBlock\n",
      "[6 ] Sequential       : 2   layers\n",
      "      ResBlock\n",
      "      ResBlock\n",
      "[7 ] Sequential       : 2   layers\n",
      "      ResBlock\n",
      "      ResBlock\n",
      "[8 ] AdaptiveAvgPool2d: 1   layers\n",
      "[9 ] Flatten          : 1   layers\n",
      "[10] Dropout          : 1   layers\n",
      "[11] Linear           : 1   layers\n"
     ]
    }
   ],
   "source": [
    "arch_summary(xresnet18,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hmm... those are indeed `ResBlocks`, but what is `ResBlock`? Often it's good idea to print out model specific blocks, as sometimes, no. of input/output channels is the novelty of it (eg. WideResnet). We can use our `get_module` method for this which requires you to pass in list of indices to reach that block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResBlock(\n",
       "  (convpath): Sequential(\n",
       "    (0): ConvLayer(\n",
       "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (1): ConvLayer(\n",
       "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (idpath): Sequential()\n",
       "  (act): ReLU(inplace=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_module(xresnet18,[4,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Residual Block](images/residual_block.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to [ResNet](https://arxiv.org/abs/1512.03385), we should have two weight layers, an identity (skip-connection) block and activation (ReLU), which is exactly `ResBlock` implements, with many [tweaks](https://arxiv.org/abs/1812.01187) introduced in the following years to improve the performance. A `ConvLayer` in fastai is Conv2D --> BatchNorm --> activation (ReLU). For the other variants of xresnet, we'll have exact same architecture but with more \"groups\" of `ResBlock`, such as\n",
    "```python\n",
    "def xresnet34 (pretrained=False, **kwargs): return _xresnet(pretrained, 1, [3, 4,  6, 3], **kwargs)\n",
    "def xresnet50 (pretrained=False, **kwargs): return _xresnet(pretrained, 4, [3, 4,  6, 3], **kwargs)\n",
    "def xresnet101(pretrained=False, **kwargs): return _xresnet(pretrained, 4, [3, 4, 23, 3], **kwargs)\n",
    "def xresnet152(pretrained=False, **kwargs): return _xresnet(pretrained, 4, [3, 8, 36, 3], **kwargs)\n",
    "```\n",
    "\n",
    "`xresnet34` will have 4 groups having `[3, 4, 6, 3]` no. of `ResBlocks` and so on. We do get other variants of these base architecutures but as they're still experimental, I'll skip them for now. Now let's have a look at some architectures from torchvision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNasNet (torchvision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import MNASNet\n",
    "mnasnet = MNASNet(1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First 7 layers are stem of the network while 8 to 13 seems like some specific blocks of this architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 ] Conv2d           : 1   layers\n",
      "[1 ] BatchNorm2d      : 1   layers\n",
      "[2 ] ReLU             : 1   layers\n",
      "[3 ] Conv2d           : 1   layers\n",
      "[4 ] BatchNorm2d      : 1   layers\n",
      "[5 ] ReLU             : 1   layers\n",
      "[6 ] Conv2d           : 1   layers\n",
      "[7 ] BatchNorm2d      : 1   layers\n",
      "[8 ] Sequential       : 3   layers\n",
      "[9 ] Sequential       : 3   layers\n",
      "[10] Sequential       : 3   layers\n",
      "[11] Sequential       : 2   layers\n",
      "[12] Sequential       : 4   layers\n",
      "[13] Sequential       : 1   layers\n",
      "[14] Conv2d           : 1   layers\n",
      "[15] BatchNorm2d      : 1   layers\n",
      "[16] ReLU             : 1   layers\n"
     ]
    }
   ],
   "source": [
    "arch_summary(mnasnet,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 ] _InvertedResidual: 8   layers\n",
      "[1 ] _InvertedResidual: 8   layers\n",
      "[2 ] _InvertedResidual: 8   layers\n"
     ]
    }
   ],
   "source": [
    "arch_summary(mnasnet,[0,8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yup, they're `InvertedResidual` blocks. Let's find out what is `InvertedResidualBlock`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_InvertedResidual(\n",
       "  (layers): Sequential(\n",
       "    (0): Conv2d(16, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(48, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)\n",
       "    (4): BatchNorm2d(48, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (7): BatchNorm2d(24, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_module(mnasnet,[0,8,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/inverted_residual.png\" alt=\"Inverted Residual\" style=\"width:50%;\" />\n",
    "\n",
    "If you spot the difference, Residual Blocks have a fat input block being shrunk down before performing actual 3 &times; 3 convolution whereas inverted residuals have exact opposite picture.\n",
    "\n",
    "A compact input block is first expanded, the convolution op is performed and again that block is compressed back to a compact version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WideResnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import wide_resnet50_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 ] (conv1)    Conv2d           : 1   layers\n",
      "[1 ] (bn1)      BatchNorm2d      : 1   layers\n",
      "[2 ] (relu)     ReLU             : 1   layers\n",
      "[3 ] (maxpool)  MaxPool2d        : 1   layers\n",
      "[4 ] (layer1)   Sequential       : 3   layers\n",
      "[5 ] (layer2)   Sequential       : 4   layers\n",
      "[6 ] (layer3)   Sequential       : 6   layers\n",
      "[7 ] (layer4)   Sequential       : 3   layers\n",
      "[8 ] (avgpool)  AdaptiveAvgPool2d: 1   layers\n",
      "[9 ] (fc)       Linear           : 1   layers\n"
     ]
    }
   ],
   "source": [
    "arch_summary(wide_resnet50_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look at the sequential layers, they do have no. of children exact similar to `resnet50`, while the key difference here is no. of input and output channels of their special block. Let's figure out what it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 ] Bottleneck       : 9   layers\n",
      "[1 ] Bottleneck       : 7   layers\n",
      "[2 ] Bottleneck       : 7   layers\n"
     ]
    }
   ],
   "source": [
    "arch_summary(wide_resnet50_2,[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the module names listed above to get required module, but you might need to take care of instantiating an object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 ] Bottleneck       : 9   layers\n",
      "[1 ] Bottleneck       : 7   layers\n",
      "[2 ] Bottleneck       : 7   layers\n"
     ]
    }
   ],
   "source": [
    "arch_summary(wide_resnet50_2().layer1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed earlier, we'll be using `get_module` to find exact definition of `Bottleneck` block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bottleneck(\n",
       "  (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (downsample): Sequential(\n",
       "    (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_module(wide_resnet50_2,[4,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare it with original `resnet50`. The idea proposed by `WideResnet` was having more channels in the bottleneck layers to exploit the parallelism offered by GPUs. Thus wideresnets take lesser time to train and to reach the error rate achieved by resnets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bottleneck(\n",
       "  (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (downsample): Sequential(\n",
       "    (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_module(resnet50,[4,0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
