---

title: Core

keywords: fastai
sidebar: home_sidebar

summary: "Core utility functions used in the library"
description: "Core utility functions used in the library"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/core.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="get_module" class="doc_header"><code>get_module</code><a href="https://github.com/Kshitij09/fast_impl/tree/master/fast_impl/core.py#L13" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>get_module</code>(<strong><code>o</code></strong>, <strong><code>i</code></strong>)</p>
</blockquote>
<p>Recursively get the module from list of indices</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Most of the times, we want to extract nested module in architecture; while some modules support indexing (Sequential), some don't. This function enables you to access nested modules in a numpy-like indexing. When coupled with <a href="/fast_impl/core#arch_summary"><code>arch_summary</code></a>, we can effortlessly explore the pytorch models.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="arch_summary" class="doc_header"><code>arch_summary</code><a href="https://github.com/Kshitij09/fast_impl/tree/master/fast_impl/core.py#L22" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>arch_summary</code>(<strong><code>arch</code></strong>, <strong><code>idx</code></strong>=<em><code>None</code></em>, <strong><code>verbose</code></strong>:<code>bool</code>=<em><code>False</code></em>)</p>
</blockquote>
<p>Short architecture summary, used for holistic understanding of model
Args:
    arch: a function or model object
    idx (int,list): an integer or list of indices to reach desired module in the architecture
    verbose (bool): If True, will list the names of sub-modules</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Examples">Examples<a class="anchor-link" href="#Examples"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>densenet121 from torchvision has first <code>_DenseLayer</code> at index [0,4,0], we can look at its brief summary as follows:</p>
<p><em>(NB: densenet121 implementation is divided into two modules, body and head, directly skipping to body)</em></p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">arch_summary</span><span class="p">(</span><span class="n">densenet121</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>(0 ) Conv2d           : 1   layers
(1 ) BatchNorm2d      : 1   layers
(2 ) ReLU             : 1   layers
(3 ) MaxPool2d        : 1   layers
(4 ) _DenseBlock      : 36  layers
(5 ) _Transition      : 4   layers
(6 ) _DenseBlock      : 72  layers
(7 ) _Transition      : 4   layers
(8 ) _DenseBlock      : 144 layers
(9 ) _Transition      : 4   layers
(10) _DenseBlock      : 96  layers
(11) BatchNorm2d      : 1   layers
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">arch_summary</span><span class="p">(</span><span class="n">densenet121</span><span class="p">,[</span><span class="mi">0</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>(0 ) BatchNorm2d      : 1   layers
(1 ) ReLU             : 1   layers
(2 ) Conv2d           : 1   layers
(3 ) BatchNorm2d      : 1   layers
(4 ) ReLU             : 1   layers
(5 ) Conv2d           : 1   layers
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And if you really want to know go deeper, you may set <code>verbose=True</code> and <a href="/fast_impl/core#arch_summary"><code>arch_summary</code></a> will go 2 depth down. For the simplicity, I'm keeping it to the depth of 2, since you can always have a detailed summary using <code>fastai2</code>'s patched summary method on module</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">arch_summary</span><span class="p">(</span><span class="n">densenet121</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>(0 ) Conv2d           : 1   layers
(1 ) BatchNorm2d      : 1   layers
(2 ) ReLU             : 1   layers
(3 ) MaxPool2d        : 1   layers
(4 ) _DenseBlock      : 36  layers
      _DenseLayer
      _DenseLayer
      _DenseLayer
      _DenseLayer
      _DenseLayer
      _DenseLayer
(5 ) _Transition      : 4   layers
      BatchNorm2d
      ReLU
      Conv2d
      AvgPool2d
(6 ) _DenseBlock      : 72  layers
      _DenseLayer
      _DenseLayer
      _DenseLayer
      _DenseLayer
      _DenseLayer
      _DenseLayer
      _DenseLayer
      _DenseLayer
      _DenseLayer
      _DenseLayer
      _DenseLayer
      _DenseLayer
(7 ) _Transition      : 4   layers
      BatchNorm2d
      ReLU
      Conv2d
      AvgPool2d
(8 ) _DenseBlock      : 144 layers
      _DenseLayer
      _DenseLayer
      _DenseLayer
      _DenseLayer
      _DenseLayer
      _DenseLayer
      _DenseLayer
      _DenseLayer
      _DenseLayer
      _DenseLayer
      _DenseLayer
      _DenseLayer
      _DenseLayer
      _DenseLayer
      _DenseLayer
      _DenseLayer
      _DenseLayer
      _DenseLayer
      _DenseLayer
      _DenseLayer
      _DenseLayer
      _DenseLayer
      _DenseLayer
      _DenseLayer
(9 ) _Transition      : 4   layers
      BatchNorm2d
      ReLU
      Conv2d
      AvgPool2d
(10) _DenseBlock      : 96  layers
      _DenseLayer
      _DenseLayer
      _DenseLayer
      _DenseLayer
      _DenseLayer
      _DenseLayer
      _DenseLayer
      _DenseLayer
      _DenseLayer
      _DenseLayer
      _DenseLayer
      _DenseLayer
      _DenseLayer
      _DenseLayer
      _DenseLayer
      _DenseLayer
(11) BatchNorm2d      : 1   layers
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

